{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a141f318-7bdf-4561-9971-a6ee2a528056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from small2DNet import small2DNet\n",
    "from util import add_color, colorize, colorize_gaussian, calculate_correct_loss\n",
    "from colorMNist import colorMNist\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "248d05e4-3a5c-4b76-bc4c-bdbc2266f6c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000 5000\n"
     ]
    }
   ],
   "source": [
    "# MNIST DATASET\n",
    "\n",
    "# Load data from pickle file\n",
    "cmnist_train, cmnist_val, cmnist_test = pickle.load(open(\"custom_datasets/5k/cmnist_gaussian_24.pkl\", \"rb\"))\n",
    "print(len(cmnist_train), len(cmnist_val), len(cmnist_train) + len(cmnist_val))\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = colorMNist(cmnist_train)\n",
    "val_dataset = colorMNist(cmnist_val)\n",
    "test_dataset = colorMNist(cmnist_test)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                               shuffle=True, num_workers = 0)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32,\n",
    "                                               shuffle=True, num_workers = 0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32,\n",
    "                                               shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1066f8bc-12b7-4c2f-b3a9-423146b008c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers of the model\n",
    "model_layers = [28, \"M\", 55, \"M\", 111,\"M\"]\n",
    "# model_layers = [16, \"M\", 96, \"M\", 64,\"M\"]\n",
    "# Set seed\n",
    "torch.manual_seed(12)\n",
    "# Create model\n",
    "linear_neurons = 512\n",
    "model = small2DNet(model_layers, model_layers[-2], linear_neurons)\n",
    "# Load file and save file\n",
    "# lfile = \"Gaussian2D_12\"\n",
    "sfile = \"test_1\"\n",
    "# Load model\n",
    "# model.load_state_dict(torch.load('model_saves/new_fair/'+ lfile + '.pth'))\n",
    "# Put model on gpu\n",
    "model.cuda()\n",
    "# Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24726f1-4ff2-48fd-b766-c8f7c56553bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:11<00:00,  1.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train acc and loss\t 0.34375 \t 1.9183515758514404\n",
      "Val acc and loss\t 0.587 \t 1.1486585587263107\n",
      "Epoch 2\n",
      "Train acc and loss\t 0.61775 \t 0.968812864780426\n",
      "Val acc and loss\t 0.682 \t 0.8316646795719862\n",
      "Epoch 3\n",
      "Train acc and loss\t 0.727 \t 0.7479231700897216\n",
      "Val acc and loss\t 0.813 \t 0.5903870705515146\n",
      "Epoch 4\n",
      "Train acc and loss\t 0.82275 \t 0.51640937936306\n",
      "Val acc and loss\t 0.822 \t 0.5472659189254045\n",
      "Epoch 5\n",
      "Train acc and loss\t 0.87575 \t 0.3729446861743927\n",
      "Val acc and loss\t 0.886 \t 0.4144955761730671\n",
      "Epoch 6\n",
      "Train acc and loss\t 0.90525 \t 0.30044219422340396\n",
      "Val acc and loss\t 0.911 \t 0.2913072123192251\n",
      "Epoch 7\n",
      "Train acc and loss\t 0.915 \t 0.2642312902212143\n",
      "Val acc and loss\t 0.912 \t 0.28073985676746815\n",
      "Epoch 8\n",
      "Train acc and loss\t 0.928 \t 0.2220593138486147\n",
      "Val acc and loss\t 0.944 \t 0.20308741240296513\n",
      "Epoch 9\n",
      "Train acc and loss\t 0.932 \t 0.2081288343667984\n",
      "Val acc and loss\t 0.938 \t 0.20129753509536386\n",
      "Epoch 10\n",
      "Train acc and loss\t 0.938 \t 0.1832239996343851\n",
      "Val acc and loss\t 0.941 \t 0.19355159974657\n",
      "Epoch 11\n",
      "Train acc and loss\t 0.9475 \t 0.16352523417770862\n",
      "Val acc and loss\t 0.952 \t 0.19836375175509602\n",
      "Epoch 12\n",
      "Train acc and loss\t 0.95325 \t 0.14647421538829802\n",
      "Val acc and loss\t 0.951 \t 0.17580900515895337\n",
      "Epoch 13\n",
      "Train acc and loss\t 0.9545 \t 0.14093415915966034\n",
      "Val acc and loss\t 0.944 \t 0.17279446648899466\n",
      "Epoch 14\n",
      "Train acc and loss\t 0.95925 \t 0.12873562759906054\n",
      "Val acc and loss\t 0.959 \t 0.1379760439740494\n",
      "Epoch 15\n",
      "Train acc and loss\t 0.96275 \t 0.12207940571755171\n",
      "Val acc and loss\t 0.963 \t 0.13551442086463794\n",
      "Epoch 16\n",
      "Train acc and loss\t 0.967 \t 0.10926330364495516\n",
      "Val acc and loss\t 0.959 \t 0.14960767334559932\n",
      "Epoch 17\n",
      "Train acc and loss\t 0.96825 \t 0.10345050869137049\n",
      "Val acc and loss\t 0.953 \t 0.14068782769027166\n",
      "Epoch 18\n",
      "Train acc and loss\t 0.97025 \t 0.09331753236427903\n",
      "Val acc and loss\t 0.966 \t 0.12625790901074652\n",
      "Epoch 19\n",
      "Train acc and loss\t 0.9705 \t 0.09124895090982318\n",
      "Val acc and loss\t 0.965 \t 0.11193500482477248\n",
      "Epoch 20\n",
      "Train acc and loss\t 0.97475 \t 0.081650604005903\n",
      "Val acc and loss\t 0.962 \t 0.11690512849600054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs to train\n",
    "epochs = 20\n",
    "\n",
    "# Placeholder variables to put training and validation accuracies and losses per epoch\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs), total=epochs, desc='Training'):\n",
    "    # print(\"Epoch\", epoch + 1, \"/\", epochs)\n",
    "    \n",
    "    # Update learning rate\n",
    "    # if (epoch + 1) % 20 == 0:\n",
    "    #     for g in optimizer.param_groups:\n",
    "    #         g['lr'] /= 10\n",
    "    \n",
    "    # Put model on training mode\n",
    "    model.train()\n",
    "    train_total_correct = 0\n",
    "    train_total_loss = []\n",
    "    \n",
    "    for (images, labels) in train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate number correct and loss in batch\n",
    "        correct, loss = calculate_correct_loss(model, loss_fn, images, labels)\n",
    "        \n",
    "        # print(y.shape)\n",
    "        # print(y)\n",
    "        # print(y[:][:120])\n",
    "        # y = torch.narrow(y, 1, 0, 120)\n",
    "        # print(y.shape)\n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Step function\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update amount correct and loss with current batch\n",
    "        train_total_correct += correct\n",
    "        train_total_loss.append(loss.item())\n",
    "#         break\n",
    "        \n",
    "#     break\n",
    "        \n",
    "    # Append epoch accuracy and loss\n",
    "    train_accuracies.append(train_total_correct / len(train_dataset))\n",
    "    train_losses.append(sum(train_total_loss) / len(train_total_loss))\n",
    "    \n",
    "    # Put model on evaluation mode\n",
    "    model.eval()\n",
    "    val_total_correct = 0\n",
    "    val_total_loss = []\n",
    "    \n",
    "    # Without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in val_dataloader:\n",
    "        \n",
    "            # Calculate number correct and loss in batch\n",
    "            correct, loss = calculate_correct_loss(model, loss_fn, images, labels)\n",
    "\n",
    "            # Update amount correct and loss with current batch\n",
    "            val_total_correct += correct\n",
    "            val_total_loss.append(loss.item())\n",
    "\n",
    "    # Append epoch accuracy and loss\n",
    "    val_accuracies.append(val_total_correct / len(val_dataset))\n",
    "    val_losses.append(sum(val_total_loss) / len(val_total_loss))\n",
    "    \n",
    "\n",
    "# Print accuracies and losses per epoch\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch\", i + 1)\n",
    "    print(\"Train acc and loss\\t\", train_accuracies[i], \"\\t\", train_losses[i])\n",
    "    print(\"Val acc and loss\\t\", val_accuracies[i], \"\\t\", val_losses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57b243c4-3a17-4904-8ea6-34f505a67251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "sfile = \"test_1\"\n",
    "torch.save(model.state_dict(), 'testsave/' + sfile + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ceefcc7-0d3b-49b0-b957-f7b58c023f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers of the model\n",
    "model_layers = [28, \"M\", 55, \"M\", 111,\"M\"]\n",
    "# model_layers = [16, \"M\", 96, \"M\", 64,\"M\"]\n",
    "# Create model\n",
    "model = small2DNet(model_layers, model_layers[-2], linear_neurons)\n",
    "# Load model\n",
    "model.load_state_dict(torch.load('testsave/'+ sfile + '.pth'))\n",
    "# Put model on gpu\n",
    "model.cuda()\n",
    "hi = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "473c4348-231e-412f-9368-d991121d3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:00<00:00, 383.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct 9655 / 10000 Accuracy: 0.9655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "    \n",
    "wrong_dict = {}\n",
    "right_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    wrong_dict[i] = {}\n",
    "    for j in range(10):\n",
    "        wrong_dict[i][j] = 0\n",
    "    right_dict[i] = 0\n",
    "    \n",
    "for it in range(1):\n",
    "    # Total and amount correct\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    # File to write predicted labels\n",
    "    # with open(\"predicted_labels.txt\", \"w\") as f:\n",
    "    #     f.write(\"\\n\")\n",
    "\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in tqdm(test_dataloader):\n",
    "\n",
    "            # Put images\n",
    "            images = images.cuda()\n",
    "\n",
    "            # Predicted labels\n",
    "            preds = model(images)\n",
    "\n",
    "            # Top predictions per image\n",
    "            _, top_preds = torch.max(preds, 1)\n",
    "\n",
    "            # Predictions and images back on cpu\n",
    "            top_preds = top_preds.cpu()\n",
    "            images = images.cpu()\n",
    "            \n",
    "            # Check the predicted\n",
    "            for i in range(len(labels)):\n",
    "                if top_preds[i].item() == labels[i].item():\n",
    "                    right_dict[top_preds[i].item()] += 1\n",
    "                else:\n",
    "                    wrong_dict[labels[i].item()][top_preds[i].item()] += 1\n",
    "\n",
    "            # Amount of correct predictions\n",
    "            predictions = [top_preds[i].item() == labels[i].item() for i in range(len(labels))]\n",
    "            correct = np.sum(predictions)\n",
    "\n",
    "    #         # Show batch images\n",
    "    #         fig, axs = plt.subplots(4,8, figsize=(28, 28), facecolor='w', edgecolor='k')\n",
    "    #         fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "    #         axs = axs.ravel()\n",
    "    #         for i in range(len(images)):\n",
    "    #             axs[i].imshow(images[i].permute(1, 2, 0))\n",
    "\n",
    "    #         break\n",
    "\n",
    "            # Update total correct and total images\n",
    "            test_correct += correct\n",
    "            test_total += len(images)\n",
    "\n",
    "\n",
    "    print(\"Correct\", test_correct, \"/\", test_total, \"Accuracy:\", test_correct / test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78166f1d-bdec-47a3-a8ee-695dc878054d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

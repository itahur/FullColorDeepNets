{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a141f318-7bdf-4561-9971-a6ee2a528056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from small2DNet import small2DNet\n",
    "from small3DNet import small3DNet\n",
    "from util import add_color, colorize, colorize_gaussian, calculate_correct_loss\n",
    "from colorMNist import colorMNist\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1066f8bc-12b7-4c2f-b3a9-423146b008c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed: 100%|██████████| 6/6 [01:36<00:00, 16.01s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed: 100%|██████████| 6/6 [01:36<00:00, 16.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed: 100%|██████████| 6/6 [01:35<00:00, 15.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed: 100%|██████████| 6/6 [01:34<00:00, 15.68s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed: 100%|██████████| 6/6 [01:32<00:00, 15.41s/it]\n"
     ]
    }
   ],
   "source": [
    "for ds in [0, 12, 60, 120, 1000000]:\n",
    "    print(ds)\n",
    "    textfill = \"\"\n",
    "    if ds == 0:\n",
    "        textfill = \"cmnist_deterministic\"\n",
    "    elif ds == 1000000:\n",
    "        textfill = \"cmnist_gaussian_uniform\"\n",
    "    else:\n",
    "        textfill = \"cmnist_gaussian_\" + str(ds)\n",
    "    \n",
    "    # for hs in [\"0\", \"90\", \"180\", \"270\"]:\n",
    "    #     print(hs)\n",
    "    textfill = \"color_uniform\"\n",
    "    # if hs != \"0\":\n",
    "    #     textfill = textfill + \"_\" + hs\n",
    "\n",
    "    sfile_fill = str(ds) if ds != 1000000 else \"uniform\"\n",
    "\n",
    "    ds_size = \"5k\"\n",
    "\n",
    "    # Load data from pickle file\n",
    "    with open(\"custom_datasets/\" + str(ds_size) + \"/\" + textfill + \".pkl\", \"rb\") as f:\n",
    "        cmnist_train, cmnist_val, cmnist_test = pickle.load(f)\n",
    "\n",
    "        # Create datasets\n",
    "        train_dataset = colorMNist(cmnist_train)\n",
    "        val_dataset = colorMNist(cmnist_val)\n",
    "        test_dataset = colorMNist(cmnist_test)\n",
    "\n",
    "        # Dataloaders\n",
    "        train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers = 0)\n",
    "        val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers = 0)\n",
    "        test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers = 0)\n",
    "\n",
    "        for iteration in tqdm(range(2, 13, 2), total=6, desc=\"Seed\"):\n",
    "            # print(\"Seed:\", iteration)\n",
    "            # 2D layers\n",
    "            model_layers2 = [84, \"M\", 165, \"M\", 333, \"M\"]\n",
    "            # 3D layers\n",
    "            model_layers3 = [32, \"M\", 64, \"M\", 128, \"M\"]\n",
    "            features = [[1, 1], [3, 1, 1]]\n",
    "            # Set seed\n",
    "            torch.manual_seed(iteration)\n",
    "            # Create model\n",
    "            model = small3DNet(model_layers3, model_layers3[-2], features[1])\n",
    "            mtype = len(model.features[0].kernel_size)\n",
    "            # Load file and save file\n",
    "            lfile = \"Gaussian\" + str(mtype) + \"D_\" + sfile_fill\n",
    "            sfile = \"C-Gaussian\" + str(mtype) + \"D_\" + sfile_fill\n",
    "            # Load model\n",
    "            model.load_state_dict(torch.load('Experiments/cmnist/model_saves/8/' + str(ds_size) + '/' + str(iteration) + '/'+ lfile + '.pth'))\n",
    "            # Put model on gpu\n",
    "            model.cuda()\n",
    "            # Loss function\n",
    "            loss_fn = torch.nn.CrossEntropyLoss()\n",
    "            # Optimizer\n",
    "            optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "            # Freeze weights\n",
    "            children = [x for x in model.children()]\n",
    "            for x in children[0]:\n",
    "                for param in x.parameters():\n",
    "                    param.requires_grad = False\n",
    "\n",
    "            # Number of epochs to train\n",
    "            epochs = 20\n",
    "\n",
    "            # Placeholder variables to put training and validation accuracies and losses per epoch\n",
    "            train_accuracies = []\n",
    "            train_losses = []\n",
    "            val_accuracies = []\n",
    "            val_losses = []\n",
    "\n",
    "            # for epoch in tqdm(range(epochs), total=epochs, desc='Training'):\n",
    "            for epoch in range(epochs):\n",
    "\n",
    "                # Put model on training mode\n",
    "                model.train()\n",
    "                train_total_correct = 0\n",
    "                train_total_loss = []\n",
    "\n",
    "                for (images, labels) in train_dataloader:\n",
    "                    # Zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # Calculate number correct and loss in batch\n",
    "                    correct, loss = calculate_correct_loss(model, loss_fn, images, labels, model_type=mtype)\n",
    "\n",
    "                    # Backpropagation\n",
    "                    loss.backward()\n",
    "                    # Step function\n",
    "                    optimizer.step()\n",
    "\n",
    "                    # Update amount correct and loss with current batch\n",
    "                    train_total_correct += correct\n",
    "                    train_total_loss.append(loss.item())\n",
    "\n",
    "                # Append epoch accuracy and loss\n",
    "                train_accuracies.append(train_total_correct / len(train_dataset))\n",
    "                train_losses.append(sum(train_total_loss) / len(train_total_loss))\n",
    "\n",
    "                # Put model on evaluation mode\n",
    "                model.eval()\n",
    "                val_total_correct = 0\n",
    "                val_total_loss = []\n",
    "\n",
    "                # Without gradient calculation\n",
    "                with torch.no_grad():\n",
    "                    for (images, labels) in val_dataloader:\n",
    "\n",
    "                        # Calculate number correct and loss in batch\n",
    "                        correct, loss = calculate_correct_loss(model, loss_fn, images, labels, model_type=mtype)\n",
    "\n",
    "                        # Update amount correct and loss with current batch\n",
    "                        val_total_correct += correct\n",
    "                        val_total_loss.append(loss.item())\n",
    "\n",
    "                # Append epoch accuracy and loss\n",
    "                val_accuracies.append(val_total_correct / len(val_dataset))\n",
    "                val_losses.append(sum(val_total_loss) / len(val_total_loss))\n",
    "\n",
    "            with open('Experiments/cmnist/trainvalAccs/best/' + str(ds_size) + '/' + str(iteration) + '/' + sfile + '.txt', 'w') as f:\n",
    "                for i in range(epochs):\n",
    "                    f.write(\"Epoch \" + str(i + 1) + \"\\n\")\n",
    "                    f.write(\"Train acc and loss\\t\" + str(train_accuracies[i]) + \"\\t\" + str(train_losses[i]) + \"\\n\")\n",
    "                    f.write(\"Val acc and loss\\t\" + str(val_accuracies[i]) + \"\\t\" + str(val_losses[i]) + \"\\n\")\n",
    "\n",
    "            # Save the model\n",
    "            torch.save(model.state_dict(), 'Experiments/cmnist/model_saves/best/' + str(ds_size) + '/' + str(iteration) + '/' + sfile + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581d261b-87a6-4977-a97a-60462dabf937",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

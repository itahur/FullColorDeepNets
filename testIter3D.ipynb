{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52a56a1c-fdd0-4b4f-b119-1115884ee18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from separateChannel3DNet import separateChannel3DNet\n",
    "from twoChannel3DNet import twoChannel3DNet\n",
    "from colorMNist import colorMNist\n",
    "import torch\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "07770a33-c688-4743-8819-118cd7277d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def avg_acc(x, y, mtype, dataset_length, n_exp, model_layers1, model_layers2, features, mix, hue_shift=-1):\n",
    "    accuracies = []\n",
    "    for iteration in tqdm(range(2, 13, 2), total=6, desc=f\"{x} {y} {mtype} {dataset_length}\"):\n",
    "        # Load dataset\n",
    "        with open(\"custom_datasets/\" + str(dataset_length) + '/' + y + \".pkl\", \"rb\") as f:\n",
    "            cmnist_train, cmnist_val, cmnist_test = pickle.load(f)\n",
    "            test_dataset = colorMNist(cmnist_test)\n",
    "            test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers = 0)\n",
    "\n",
    "            # Layers of the model\n",
    "            model_layers = model_layers1 if mtype == 1 else model_layers2\n",
    "            # Create model\n",
    "            model = separateChannel3DNet(model_layers, model_layers[-2], features, mix) if mtype == 1 else twoChannel3DNet(model_layers, model_layers[-2], features, mix)\n",
    "            # Load file\n",
    "            extra = \"\" if hue_shift == -1 else \"_\" + str(hue_shift)\n",
    "            lfile = str(mtype) + \"-Gaussian3D_\" + x + extra\n",
    "            # Load model\n",
    "            model.load_state_dict(torch.load('Experiments/conv/model_saves/' + str(n_exp) + '/' + str(dataset_length)\n",
    "                                             + '/' + str(iteration) + '/' + lfile + '.pth'))\n",
    "            # Put model on gpu\n",
    "            model.cuda()\n",
    "\n",
    "            # Total and amount correct\n",
    "            test_correct = 0\n",
    "            test_total = 0\n",
    "\n",
    "            # Put the model in evaluation mode\n",
    "            model.eval()\n",
    "\n",
    "            # Without gradient calculation\n",
    "            with torch.no_grad():\n",
    "                for (images, labels) in test_dataloader:\n",
    "\n",
    "                    # Add extra dimension for the network\n",
    "                    images = images.unsqueeze(1)\n",
    "\n",
    "                    # Put images\n",
    "                    images = images.cuda()\n",
    "\n",
    "                    # Predicted labels\n",
    "                    preds = model(images)\n",
    "\n",
    "                    # Top predictions per image\n",
    "                    _, top_preds = torch.max(preds, 1)\n",
    "\n",
    "                    # Predictions and images back on cpu\n",
    "                    top_preds = top_preds.cpu()\n",
    "                    images = images.cpu()\n",
    "\n",
    "                    # Amount of correct predictions\n",
    "                    predictions = [top_preds[i].item() == labels[i].item() for i in range(len(labels))]\n",
    "                    correct = np.sum(predictions)\n",
    "\n",
    "                    # Update total correct and total images\n",
    "                    test_correct += correct\n",
    "                    test_total += len(images)\n",
    "\n",
    "            accuracies.append(test_correct / test_total)\n",
    "    return accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61872287-127c-4fa1-8147-9ee28fdc9146",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0 cmnist_deterministic 1 1k: 100%|██████████| 6/6 [00:11<00:00,  1.93s/it]\n",
      "0 cmnist_deterministic 2 1k: 100%|██████████| 6/6 [00:11<00:00,  1.94s/it]\n",
      "12 cmnist_gaussian_12 1 1k: 100%|██████████| 6/6 [00:11<00:00,  1.94s/it]\n",
      "12 cmnist_gaussian_12 2 1k: 100%|██████████| 6/6 [00:11<00:00,  1.98s/it]\n",
      "60 cmnist_gaussian_60 1 1k: 100%|██████████| 6/6 [00:11<00:00,  1.95s/it]\n",
      "60 cmnist_gaussian_60 2 1k: 100%|██████████| 6/6 [00:11<00:00,  1.95s/it]\n",
      "120 cmnist_gaussian_120 1 1k: 100%|██████████| 6/6 [00:11<00:00,  1.94s/it]\n",
      "120 cmnist_gaussian_120 2 1k: 100%|██████████| 6/6 [00:11<00:00,  1.98s/it]\n",
      "uniform cmnist_gaussian_uniform 1 1k: 100%|██████████| 6/6 [00:11<00:00,  1.88s/it]\n",
      "uniform cmnist_gaussian_uniform 2 1k: 100%|██████████| 6/6 [00:11<00:00,  1.95s/it]\n",
      "0 cmnist_deterministic 1 2k: 100%|██████████| 6/6 [00:11<00:00,  1.91s/it]\n",
      "0 cmnist_deterministic 2 2k: 100%|██████████| 6/6 [00:11<00:00,  1.97s/it]\n",
      "12 cmnist_gaussian_12 1 2k: 100%|██████████| 6/6 [00:11<00:00,  1.89s/it]\n",
      "12 cmnist_gaussian_12 2 2k: 100%|██████████| 6/6 [00:11<00:00,  1.98s/it]\n",
      "60 cmnist_gaussian_60 1 2k: 100%|██████████| 6/6 [00:11<00:00,  1.90s/it]\n",
      "60 cmnist_gaussian_60 2 2k: 100%|██████████| 6/6 [00:11<00:00,  1.96s/it]\n",
      "120 cmnist_gaussian_120 1 2k: 100%|██████████| 6/6 [00:11<00:00,  1.90s/it]\n",
      "120 cmnist_gaussian_120 2 2k: 100%|██████████| 6/6 [00:11<00:00,  1.97s/it]\n",
      "uniform cmnist_gaussian_uniform 1 2k: 100%|██████████| 6/6 [00:11<00:00,  1.90s/it]\n",
      "uniform cmnist_gaussian_uniform 2 2k: 100%|██████████| 6/6 [00:11<00:00,  1.97s/it]\n",
      "0 cmnist_deterministic 1 5k: 100%|██████████| 6/6 [00:12<00:00,  2.06s/it]\n",
      "0 cmnist_deterministic 2 5k: 100%|██████████| 6/6 [00:12<00:00,  2.12s/it]\n",
      "12 cmnist_gaussian_12 1 5k: 100%|██████████| 6/6 [00:12<00:00,  2.04s/it]\n",
      "12 cmnist_gaussian_12 2 5k: 100%|██████████| 6/6 [00:12<00:00,  2.11s/it]\n",
      "60 cmnist_gaussian_60 1 5k: 100%|██████████| 6/6 [00:12<00:00,  2.05s/it]\n",
      "60 cmnist_gaussian_60 2 5k: 100%|██████████| 6/6 [00:12<00:00,  2.14s/it]\n",
      "120 cmnist_gaussian_120 1 5k: 100%|██████████| 6/6 [00:12<00:00,  2.04s/it]\n",
      "120 cmnist_gaussian_120 2 5k: 100%|██████████| 6/6 [00:12<00:00,  2.12s/it]\n",
      "uniform cmnist_gaussian_uniform 1 5k: 100%|██████████| 6/6 [00:12<00:00,  2.12s/it]\n",
      "uniform cmnist_gaussian_uniform 2 5k: 100%|██████████| 6/6 [00:12<00:00,  2.16s/it]\n",
      "0 cmnist_deterministic 1 10k: 100%|██████████| 6/6 [00:14<00:00,  2.41s/it]\n",
      "0 cmnist_deterministic 2 10k: 100%|██████████| 6/6 [00:14<00:00,  2.49s/it]\n",
      "12 cmnist_gaussian_12 1 10k: 100%|██████████| 6/6 [00:14<00:00,  2.40s/it]\n",
      "12 cmnist_gaussian_12 2 10k: 100%|██████████| 6/6 [00:14<00:00,  2.49s/it]\n",
      "60 cmnist_gaussian_60 1 10k: 100%|██████████| 6/6 [00:14<00:00,  2.38s/it]\n",
      "60 cmnist_gaussian_60 2 10k: 100%|██████████| 6/6 [00:14<00:00,  2.50s/it]\n",
      "120 cmnist_gaussian_120 1 10k: 100%|██████████| 6/6 [00:15<00:00,  2.50s/it]\n",
      "120 cmnist_gaussian_120 2 10k: 100%|██████████| 6/6 [00:14<00:00,  2.48s/it]\n",
      "uniform cmnist_gaussian_uniform 1 10k: 100%|██████████| 6/6 [00:14<00:00,  2.41s/it]\n",
      "uniform cmnist_gaussian_uniform 2 10k: 100%|██████████| 6/6 [00:14<00:00,  2.47s/it]\n",
      "0 cmnist_deterministic 1 20k: 100%|██████████| 6/6 [00:18<00:00,  3.03s/it]\n",
      "0 cmnist_deterministic 2 20k: 100%|██████████| 6/6 [00:18<00:00,  3.13s/it]\n",
      "12 cmnist_gaussian_12 1 20k: 100%|██████████| 6/6 [00:18<00:00,  3.03s/it]\n",
      "12 cmnist_gaussian_12 2 20k: 100%|██████████| 6/6 [00:18<00:00,  3.14s/it]\n",
      "60 cmnist_gaussian_60 1 20k: 100%|██████████| 6/6 [00:18<00:00,  3.08s/it]\n",
      "60 cmnist_gaussian_60 2 20k: 100%|██████████| 6/6 [00:18<00:00,  3.15s/it]\n",
      "120 cmnist_gaussian_120 1 20k: 100%|██████████| 6/6 [00:18<00:00,  3.00s/it]\n",
      "120 cmnist_gaussian_120 2 20k: 100%|██████████| 6/6 [00:18<00:00,  3.11s/it]\n",
      "uniform cmnist_gaussian_uniform 1 20k: 100%|██████████| 6/6 [00:18<00:00,  3.04s/it]\n",
      "uniform cmnist_gaussian_uniform 2 20k: 100%|██████████| 6/6 [00:18<00:00,  3.14s/it]\n",
      "0 cmnist_deterministic 1 60k: 100%|██████████| 6/6 [00:34<00:00,  5.67s/it]\n",
      "0 cmnist_deterministic 2 60k: 100%|██████████| 6/6 [00:34<00:00,  5.73s/it]\n",
      "12 cmnist_gaussian_12 1 60k: 100%|██████████| 6/6 [00:33<00:00,  5.63s/it]\n",
      "12 cmnist_gaussian_12 2 60k: 100%|██████████| 6/6 [00:34<00:00,  5.73s/it]\n",
      "60 cmnist_gaussian_60 1 60k: 100%|██████████| 6/6 [00:33<00:00,  5.65s/it]\n",
      "60 cmnist_gaussian_60 2 60k: 100%|██████████| 6/6 [00:34<00:00,  5.76s/it]\n",
      "120 cmnist_gaussian_120 1 60k: 100%|██████████| 6/6 [00:34<00:00,  5.73s/it]\n",
      "120 cmnist_gaussian_120 2 60k: 100%|██████████| 6/6 [00:34<00:00,  5.76s/it]\n",
      "uniform cmnist_gaussian_uniform 1 60k: 100%|██████████| 6/6 [00:34<00:00,  5.75s/it]\n",
      "uniform cmnist_gaussian_uniform 2 60k: 100%|██████████| 6/6 [00:35<00:00,  5.85s/it]\n"
     ]
    }
   ],
   "source": [
    "datasets = [[\"0\", \"cmnist_deterministic\"], [\"12\", \"cmnist_gaussian_12\"], [\"60\", \"cmnist_gaussian_60\"],\n",
    "            [\"120\", \"cmnist_gaussian_120\"], [\"uniform\", \"cmnist_gaussian_uniform\"]]\n",
    "dataset_lengths = [\"1k\", \"2k\", \"5k\", \"10k\", \"20k\", \"60k\"]\n",
    "n_exp = 2\n",
    "model_layers1 = [32, \"M\", 64, \"M\", 128, \"M\"]\n",
    "model_layers2 = [32, \"M\", 64, \"M\", 128, \"M\"]\n",
    "features = [3, 1, 1]\n",
    "mix = True\n",
    "\n",
    "for dl in dataset_lengths:\n",
    "    tot_accs1 = []\n",
    "    tot_accs2 = []\n",
    "    for x, y in datasets:\n",
    "        tot_accs1.append(avg_acc(x, y, 1, dl, n_exp, model_layers1, model_layers2, features, mix))\n",
    "        tot_accs2.append(avg_acc(x, y, 2, dl, n_exp, model_layers2, model_layers2, features, mix))\n",
    "\n",
    "    y1_mean = []\n",
    "    y1_std = []\n",
    "    y2_mean = []\n",
    "    y2_std = []\n",
    "    for i in range(len(tot_accs1)):\n",
    "        y1_mean.append(np.mean(tot_accs1[i]))\n",
    "        y1_std.append(np.std(tot_accs1[i]))\n",
    "        y2_mean.append(np.mean(tot_accs2[i]))\n",
    "        y2_std.append(np.std(tot_accs2[i]))\n",
    "\n",
    "    np.savetxt(\"Experiments/conv/plots/\" + str(n_exp) + \"/\" + dl + \"_1cv2c.txt\", [y1_mean, y1_std, y2_mean, y2_std])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb29f9a8-b67f-45c0-9f93-90795e3d056f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

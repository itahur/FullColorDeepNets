{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a141f318-7bdf-4561-9971-a6ee2a528056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from twoChannel3DNet import twoChannel3DNet\n",
    "# import twoChannel3DNet\n",
    "from util import add_color, colorize, colorize_gaussian, calculate_correct_loss\n",
    "from colorMNist import colorMNist\n",
    "import random\n",
    "import colorsys\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a47277-f6ea-4ac7-86bd-0710891586a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(twoChannel3DNet)\n",
    "hi = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "9a19e349-faac-402c-9cc3-65c6d4f38c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000 5000\n"
     ]
    }
   ],
   "source": [
    "# Load data from pickle file\n",
    "cmnist_train, cmnist_val, cmnist_test = pickle.load(open(\"custom_datasets/color_uniform.pkl\", \"rb\"))\n",
    "print(len(cmnist_train), len(cmnist_val), len(cmnist_train) + len(cmnist_val))\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = colorMNist(cmnist_train)\n",
    "val_dataset = colorMNist(cmnist_val)\n",
    "test_dataset = colorMNist(cmnist_test)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                               shuffle=True, num_workers = 0)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32,\n",
    "                                               shuffle=True, num_workers = 0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32,\n",
    "                                               shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1066f8bc-12b7-4c2f-b3a9-423146b008c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers of the model\n",
    "model_layers = [8, 8, \"M\", 16,\"M\"]\n",
    "# Create model\n",
    "model = twoChannel3DNet(model_layers, 16)\n",
    "# Load file and save file\n",
    "lfile = \"2CGaussian3D_36\"\n",
    "sfile = \"C-2CGaussian3D_36\"\n",
    "# # Load model\n",
    "model.load_state_dict(torch.load('model_saves/TwoChannel/' + lfile + '.pth'))\n",
    "# Put model on gpu\n",
    "model.cuda()\n",
    "# Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b76d0a9c-ecac-4e93-b0e1-b1bd457251bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze weights\n",
    "children = [x for x in model.children()]\n",
    "for x in children[0]:\n",
    "    for param in x.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b24726f1-4ff2-48fd-b766-c8f7c56553bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.50it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 260.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.47it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 255.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.66it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 271.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.79it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 263.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.57it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 261.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 59.24it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 244.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.85it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 261.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.47it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 241.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.67it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 265.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 / 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 125/125 [00:02<00:00, 58.40it/s]\n",
      "100%|██████████| 32/32 [00:00<00:00, 320.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train acc and loss\t 0.85125 \t 0.7409883699342609\n",
      "Val acc and loss\t 0.999 \t 0.01124404979054816\n",
      "Epoch 2\n",
      "Train acc and loss\t 0.99225 \t 0.03481468350440264\n",
      "Val acc and loss\t 1.0 \t 0.0051407317023404175\n",
      "Epoch 3\n",
      "Train acc and loss\t 0.99625 \t 0.016781851520761847\n",
      "Val acc and loss\t 1.0 \t 0.0035313307998876553\n",
      "Epoch 4\n",
      "Train acc and loss\t 0.998 \t 0.009544096610974521\n",
      "Val acc and loss\t 0.999 \t 0.0026017841641987616\n",
      "Epoch 5\n",
      "Train acc and loss\t 0.99925 \t 0.006599170670378953\n",
      "Val acc and loss\t 1.0 \t 0.0023724187026346044\n",
      "Epoch 6\n",
      "Train acc and loss\t 0.99925 \t 0.005113052575150504\n",
      "Val acc and loss\t 1.0 \t 0.0018756061593023787\n",
      "Epoch 7\n",
      "Train acc and loss\t 0.9995 \t 0.004484650751342997\n",
      "Val acc and loss\t 0.999 \t 0.003527627369521724\n",
      "Epoch 8\n",
      "Train acc and loss\t 0.99975 \t 0.003290768977603875\n",
      "Val acc and loss\t 1.0 \t 0.001835124978128988\n",
      "Epoch 9\n",
      "Train acc and loss\t 0.99925 \t 0.003290656013879925\n",
      "Val acc and loss\t 1.0 \t 0.0014113304962961593\n",
      "Epoch 10\n",
      "Train acc and loss\t 1.0 \t 0.002994643862475641\n",
      "Val acc and loss\t 1.0 \t 0.001670997132436014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs to train\n",
    "epochs = 10\n",
    "\n",
    "# Placeholder variables to put training and validation accuracies and losses per epoch\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(\"Epoch\", epoch + 1, \"/\", epochs)\n",
    "    \n",
    "    # Put model on training mode\n",
    "    model.train()\n",
    "    train_total_correct = 0\n",
    "    train_total_loss = []\n",
    "    \n",
    "    for (images, labels) in tqdm(train_dataloader):\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate number correct and loss in batch\n",
    "        correct, loss = calculate_correct_loss(model, loss_fn, images, labels, model_type=3)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Step function\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update amount correct and loss with current batch\n",
    "        train_total_correct += correct\n",
    "        train_total_loss.append(loss.item())\n",
    "        \n",
    "    # Append epoch accuracy and loss\n",
    "    train_accuracies.append(train_total_correct / len(train_dataset))\n",
    "    train_losses.append(sum(train_total_loss) / len(train_total_loss))\n",
    "    \n",
    "    # Put model on evaluation mode\n",
    "    model.eval()\n",
    "    val_total_correct = 0\n",
    "    val_total_loss = []\n",
    "    \n",
    "    # Without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in tqdm(val_dataloader):\n",
    "        \n",
    "            # Calculate number correct and loss in batch\n",
    "            correct, loss = calculate_correct_loss(model, loss_fn, images, labels, model_type=3)\n",
    "\n",
    "            # Update amount correct and loss with current batch\n",
    "            val_total_correct += correct\n",
    "            val_total_loss.append(loss.item())\n",
    "\n",
    "    # Append epoch accuracy and loss\n",
    "    val_accuracies.append(val_total_correct / len(val_dataset))\n",
    "    val_losses.append(sum(val_total_loss) / len(val_total_loss))\n",
    "    \n",
    "\n",
    "# Print accuracies and losses per epoch\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch\", i + 1)\n",
    "    print(\"Train acc and loss\\t\", train_accuracies[i], \"\\t\", train_losses[i])\n",
    "    print(\"Val acc and loss\\t\", val_accuracies[i], \"\\t\", val_losses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e4afc9c0-5a61-4013-aa9a-1f101261d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainvalAccs/' + sfile + '.txt', 'w') as f:\n",
    "    for i in range(epochs):\n",
    "        f.write(\"Epoch \" + str(i + 1) + \"\\n\")\n",
    "        f.write(\"Train acc and loss\\t\" + str(train_accuracies[i]) + \"\\t\" + str(train_losses[i]) + \"\\n\")\n",
    "        f.write(\"Val acc and loss\\t\" + str(val_accuracies[i]) + \"\\t\" + str(val_losses[i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57b243c4-3a17-4904-8ea6-34f505a67251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'model_saves/ColorExperiment/'+ sfile + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b3080be7-b7ce-49bc-a324-f0020c560053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers of the model\n",
    "model_layers = [8, 8, \"M\", 16,\"M\"]\n",
    "# Create model\n",
    "model = twoChannel3DNet(model_layers, 16)\n",
    "# model = separateChannel3DNet(model_layers, 16)\n",
    "# # Load model\n",
    "model.load_state_dict(torch.load('model_saves/ColorExperiment/'+ sfile + '.pth'))\n",
    "# Put model on gpu\n",
    "model.cuda()\n",
    "hi = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "473c4348-231e-412f-9368-d991121d3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 260.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct 10000 / 10000 Accuracy: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "    \n",
    "wrong_dict = {}\n",
    "right_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    wrong_dict[i] = {}\n",
    "    for j in range(10):\n",
    "        wrong_dict[i][j] = 0\n",
    "    right_dict[i] = 0\n",
    "    \n",
    "for it in range(1):\n",
    "    # Total and amount correct\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in tqdm(test_dataloader):\n",
    "            # # Add color to each image\n",
    "            # for i in range(len(images)):\n",
    "            #     if 10 not in color_dict:\n",
    "            #         colorize(images[i], labels[i].item(), color_dict)\n",
    "            #     else:\n",
    "            #         colorize_gaussian(images[i], labels[i].item(), color_dict)\n",
    "            #     # images[i] = inv_normalize(images[i])\n",
    "\n",
    "            # Add extra dimension for the network\n",
    "            images = images.unsqueeze(1)\n",
    "\n",
    "            # print(images.shape)\n",
    "\n",
    "            # Put images\n",
    "            images = images.cuda()\n",
    "\n",
    "            # Predicted labels\n",
    "            preds = model(images)\n",
    "\n",
    "            # Top predictions per image\n",
    "            _, top_preds = torch.max(preds, 1)\n",
    "\n",
    "            # Predictions and images back on cpu\n",
    "            top_preds = top_preds.cpu()\n",
    "            images = images.cpu()\n",
    "            \n",
    "            # Check the predicted\n",
    "            for i in range(len(labels)):\n",
    "                if top_preds[i].item() == labels[i].item():\n",
    "                    right_dict[top_preds[i].item()] += 1\n",
    "                else:\n",
    "                    wrong_dict[labels[i].item()][top_preds[i].item()] += 1\n",
    "\n",
    "            # Amount of correct predictions\n",
    "            predictions = [top_preds[i].item() == labels[i].item() for i in range(len(labels))]\n",
    "            correct = np.sum(predictions)\n",
    "            \n",
    "            # if np.sum(predictions) < len(labels):\n",
    "            #     print(\"hi\")\n",
    "            #     images = images.squeeze(1)\n",
    "            #     # Show batch images\n",
    "            #     # fig, axs = plt.subplots(4,8, figsize=(28, 28), facecolor='w', edgecolor='k')\n",
    "            #     # fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "            #     # axs = axs.ravel()\n",
    "            #     # for i in range(len(images)):\n",
    "            #     #     axs[i].imshow(images[i].permute(1, 2, 0))\n",
    "                \n",
    "                \n",
    "#                 index = predictions.index(0)\n",
    "                \n",
    "#                 plt.imshow(images[index].permute(1, 2, 0))\n",
    "#                 plt.show()\n",
    "                \n",
    "#                 print(index, \"True:\", labels[index].item(), \"False:\", top_preds[index].item())\n",
    "                # break\n",
    "\n",
    "            # Update total correct and total images\n",
    "            test_correct += correct\n",
    "            test_total += len(images)\n",
    "\n",
    "\n",
    "    print(\"Correct\", test_correct, \"/\", test_total, \"Accuracy:\", test_correct / test_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc47db-b048-4b01-aa1d-df47a3abda9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in right_dict:\n",
    "    print(x, \":\", right_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09e339-9113-4cbd-ada2-f329fee7d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = []\n",
    "for i, x in enumerate(wrong_dict):\n",
    "    hm.append([])\n",
    "    for y in wrong_dict[x]:\n",
    "        hm[i].append(wrong_dict[x][y])\n",
    "    # print(x, \":\", wrong_dict[x])\n",
    "print(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff34f1-527a-4e78-a8d8-dcaaa6f1efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(hm, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35373e42-0ad7-4ac5-9389-7332fe5e961c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones([32, 1, 3, 28, 28])\n",
    "# print(og)\n",
    "\n",
    "zeros = torch.zeros([32, 1, 28, 28])\n",
    "zeros = zeros.unsqueeze(dim=2)\n",
    "# print(add)\n",
    "\n",
    "res = torch.cat([ones, zeros], dim=2)\n",
    "\n",
    "print(res.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

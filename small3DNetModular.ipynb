{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a141f318-7bdf-4561-9971-a6ee2a528056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from small3DNet import small3DNet\n",
    "from separateChannel3DNet import separateChannel3DNet\n",
    "from twoChannel3DNet import twoChannel3DNet\n",
    "from util import add_color, colorize, colorize_gaussian, calculate_correct_loss\n",
    "from colorMNist import colorMNist\n",
    "import random\n",
    "import colorsys\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32ba0e2-7ea6-49e5-bed5-b4ce66b4ff1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.init(project=\"my-test-project\", entity=\"ntahur\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bdde413-2602-4d12-95db-d0df6b9119ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a19e349-faac-402c-9cc3-65c6d4f38c73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 1000 5000\n"
     ]
    }
   ],
   "source": [
    "# Load data from pickle file\n",
    "cmnist_train, cmnist_val, cmnist_test = pickle.load(open(\"custom_datasets/5k/cmnist_gaussian_18.pkl\", \"rb\"))\n",
    "print(len(cmnist_train), len(cmnist_val), len(cmnist_train) + len(cmnist_val))\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = colorMNist(cmnist_train)\n",
    "val_dataset = colorMNist(cmnist_val)\n",
    "test_dataset = colorMNist(cmnist_test)\n",
    "\n",
    "# Dataloaders\n",
    "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=32,\n",
    "                                               shuffle=True, num_workers = 0)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32,\n",
    "                                               shuffle=True, num_workers = 0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=32,\n",
    "                                               shuffle=False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456fd9d3-3e11-417d-9a38-8dbd71ef9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor(),\n",
    "     torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='datasets/cifar10', train=True, download=False, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='datasets/cifar10', train=False, download=False, transform=transform)\n",
    "\n",
    "# Create the 80/20 train/val split\n",
    "train_split = int(0.8 * len(trainset))\n",
    "# Train dataset\n",
    "train_dataset = torch.utils.data.Subset(trainset, [i for i in range(train_split)])\n",
    "# Validation dataset\n",
    "val_dataset = torch.utils.data.Subset(trainset, [i for i in range(train_split, len(trainset))])\n",
    "print(len(train_dataset), len(val_dataset), len(train_dataset) + len(val_dataset))\n",
    "\n",
    "train_dataloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "test_dataloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1066f8bc-12b7-4c2f-b3a9-423146b008c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers of the model\n",
    "# model_layers = [8, 8, \"M\", 16,\"M\"]\n",
    "model_layers = [16, \"M\", 16, \"M\", 64,\"M\"]\n",
    "# Create model\n",
    "# Set seed\n",
    "torch.manual_seed(12)\n",
    "# Create model\n",
    "model = small3DNet(model_layers, model_layers[-2])\n",
    "# model = separateChannel3DNet(model_layers, 16)\n",
    "# Load file and save file\n",
    "# lfile = \"Gaussian3D_0\"\n",
    "sfile = \"Gaussian3D_uniform\"\n",
    "# # Load model\n",
    "# model.load_state_dict(torch.load('model_saves/new_fair/' + lfile + '.pth'))\n",
    "# Put model on gpu\n",
    "model.cuda()\n",
    "# Loss function\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76d0a9c-ecac-4e93-b0e1-b1bd457251bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze weights\n",
    "children = [x for x in model.children()]\n",
    "for x in children[0]:\n",
    "    for param in x.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b24726f1-4ff2-48fd-b766-c8f7c56553bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 20/20 [00:20<00:00,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "Train acc and loss\t 0.35575 \t 1.8737903995513916\n",
      "Val acc and loss\t 0.595 \t 1.0613581649959087\n",
      "Epoch 2\n",
      "Train acc and loss\t 0.6775 \t 0.794496253490448\n",
      "Val acc and loss\t 0.716 \t 0.6889557782560587\n",
      "Epoch 3\n",
      "Train acc and loss\t 0.75025 \t 0.6287787902355194\n",
      "Val acc and loss\t 0.79 \t 0.5571339121088386\n",
      "Epoch 4\n",
      "Train acc and loss\t 0.8135 \t 0.49315749621391297\n",
      "Val acc and loss\t 0.847 \t 0.44666180247440934\n",
      "Epoch 5\n",
      "Train acc and loss\t 0.87725 \t 0.3537417013645172\n",
      "Val acc and loss\t 0.907 \t 0.2736019673757255\n",
      "Epoch 6\n",
      "Train acc and loss\t 0.90075 \t 0.2775509526133537\n",
      "Val acc and loss\t 0.914 \t 0.29737630137242377\n",
      "Epoch 7\n",
      "Train acc and loss\t 0.921 \t 0.22388241267204284\n",
      "Val acc and loss\t 0.931 \t 0.2319986877264455\n",
      "Epoch 8\n",
      "Train acc and loss\t 0.93325 \t 0.20749437421560288\n",
      "Val acc and loss\t 0.92 \t 0.2435502142761834\n",
      "Epoch 9\n",
      "Train acc and loss\t 0.936 \t 0.1929440341889858\n",
      "Val acc and loss\t 0.95 \t 0.16520010924432427\n",
      "Epoch 10\n",
      "Train acc and loss\t 0.94225 \t 0.16198640383780002\n",
      "Val acc and loss\t 0.946 \t 0.1499257949180901\n",
      "Epoch 11\n",
      "Train acc and loss\t 0.944 \t 0.161423924818635\n",
      "Val acc and loss\t 0.958 \t 0.1362013520556502\n",
      "Epoch 12\n",
      "Train acc and loss\t 0.94825 \t 0.15711767515540123\n",
      "Val acc and loss\t 0.956 \t 0.13040588586591184\n",
      "Epoch 13\n",
      "Train acc and loss\t 0.95175 \t 0.13236245611310005\n",
      "Val acc and loss\t 0.933 \t 0.24378358060494065\n",
      "Epoch 14\n",
      "Train acc and loss\t 0.96125 \t 0.12014852076023817\n",
      "Val acc and loss\t 0.949 \t 0.16452188865514472\n",
      "Epoch 15\n",
      "Train acc and loss\t 0.9555 \t 0.12976267729699612\n",
      "Val acc and loss\t 0.952 \t 0.14717761531937867\n",
      "Epoch 16\n",
      "Train acc and loss\t 0.95975 \t 0.11344241480529309\n",
      "Val acc and loss\t 0.97 \t 0.10297934390837327\n",
      "Epoch 17\n",
      "Train acc and loss\t 0.964 \t 0.10680834191292524\n",
      "Val acc and loss\t 0.955 \t 0.1336437434074469\n",
      "Epoch 18\n",
      "Train acc and loss\t 0.96725 \t 0.09696673011034727\n",
      "Val acc and loss\t 0.965 \t 0.12137162304134108\n",
      "Epoch 19\n",
      "Train acc and loss\t 0.97025 \t 0.08686397264152765\n",
      "Val acc and loss\t 0.941 \t 0.21096203825436532\n",
      "Epoch 20\n",
      "Train acc and loss\t 0.9695 \t 0.09296225617080926\n",
      "Val acc and loss\t 0.973 \t 0.10602520772954449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Number of epochs to train\n",
    "epochs = 20\n",
    "\n",
    "# Placeholder variables to put training and validation accuracies and losses per epoch\n",
    "train_accuracies = []\n",
    "train_losses = []\n",
    "val_accuracies = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in tqdm(range(epochs), total=epochs, desc='Training'):\n",
    "    # print(\"Epoch\", epoch + 1, \"/\", epochs)\n",
    "    \n",
    "    # Update learning rate\n",
    "    # if (epoch + 1) % 3 == 0:\n",
    "    #     for g in optimizer.param_groups:\n",
    "    #         g['lr'] /= 10\n",
    "    \n",
    "    # Weights and Biases code\n",
    "    # children = [x for x in model.children()]\n",
    "    # for i, x in enumerate(children[0][0].weight):\n",
    "    #     x0 = x[0][0].cpu().detach().numpy().flatten().reshape(1, -1)\n",
    "    #     x1 = x[0][1].cpu().detach().numpy().flatten().reshape(1, -1)\n",
    "    #     x2 = x[0][2].cpu().detach().numpy().flatten().reshape(1, -1)\n",
    "    #     wandb.log({\"Uavgsim-\"+str(i): (cosine_similarity(x0, x1)[0][0] + cosine_similarity(x0, x2)[0][0] + cosine_similarity(x1, x2)[0][0]) / 3})\n",
    "    \n",
    "    # Put model on training mode\n",
    "    model.train()\n",
    "    train_total_correct = 0\n",
    "    train_total_loss = []\n",
    "    \n",
    "    for (images, labels) in train_dataloader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Calculate number correct and loss in batch\n",
    "        correct, loss = calculate_correct_loss(model, loss_fn, images, labels, model_type=3)\n",
    "        \n",
    "        # Backpropagation\n",
    "        loss.backward()\n",
    "        # Step function\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update amount correct and loss with current batch\n",
    "        train_total_correct += correct\n",
    "        train_total_loss.append(loss.item())\n",
    "        \n",
    "    # Append epoch accuracy and loss\n",
    "    train_accuracies.append(train_total_correct / len(train_dataset))\n",
    "    train_losses.append(sum(train_total_loss) / len(train_total_loss))\n",
    "    \n",
    "    # Put model on evaluation mode\n",
    "    model.eval()\n",
    "    val_total_correct = 0\n",
    "    val_total_loss = []\n",
    "    \n",
    "    # Without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in val_dataloader:\n",
    "        \n",
    "            # Calculate number correct and loss in batch\n",
    "            correct, loss = calculate_correct_loss(model, loss_fn, images, labels, model_type=3)\n",
    "\n",
    "            # Update amount correct and loss with current batch\n",
    "            val_total_correct += correct\n",
    "            val_total_loss.append(loss.item())\n",
    "\n",
    "    # Append epoch accuracy and loss\n",
    "    val_accuracies.append(val_total_correct / len(val_dataset))\n",
    "    val_losses.append(sum(val_total_loss) / len(val_total_loss))\n",
    "    \n",
    "\n",
    "# Print accuracies and losses per epoch\n",
    "for i in range(epochs):\n",
    "    print(\"Epoch\", i + 1)\n",
    "    print(\"Train acc and loss\\t\", train_accuracies[i], \"\\t\", train_losses[i])\n",
    "    print(\"Val acc and loss\\t\", val_accuracies[i], \"\\t\", val_losses[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4afc9c0-5a61-4013-aa9a-1f101261d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('trainvalAccs/' + sfile + '.txt', 'w') as f:\n",
    "    for i in range(epochs):\n",
    "        f.write(\"Epoch \" + str(i + 1) + \"\\n\")\n",
    "        f.write(\"Train acc and loss\\t\" + str(train_accuracies[i]) + \"\\t\" + str(train_losses[i]) + \"\\n\")\n",
    "        f.write(\"Val acc and loss\\t\" + str(val_accuracies[i]) + \"\\t\" + str(val_losses[i]) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "57b243c4-3a17-4904-8ea6-34f505a67251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), 'testsave/'+ sfile + '.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b3080be7-b7ce-49bc-a324-f0020c560053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Layers of the model\n",
    "model_layers = [16, \"M\", 32, \"M\", 64,\"M\"]\n",
    "# Create model\n",
    "model = small3DNet(model_layers, model_layers[-2], linear_neurons)\n",
    "# model = separateChannel3DNet(model_layers, 16)\n",
    "# # Load model\n",
    "model.load_state_dict(torch.load('model_saves/new_fair/'+ sfile + '.pth'))\n",
    "# Put model on gpu\n",
    "model.cuda()\n",
    "hi = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "473c4348-231e-412f-9368-d991121d3d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:01<00:00, 227.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct 9656 / 10000 Accuracy: 0.9656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "    \n",
    "wrong_dict = {}\n",
    "right_dict = {}\n",
    "\n",
    "for i in range(10):\n",
    "    wrong_dict[i] = {}\n",
    "    for j in range(10):\n",
    "        wrong_dict[i][j] = 0\n",
    "    right_dict[i] = 0\n",
    "    \n",
    "for it in range(1):\n",
    "    # Total and amount correct\n",
    "    test_correct = 0\n",
    "    test_total = 0\n",
    "\n",
    "    # Put the model in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Without gradient calculation\n",
    "    with torch.no_grad():\n",
    "        for (images, labels) in tqdm(test_dataloader):\n",
    "            # # Add color to each image\n",
    "            # for i in range(len(images)):\n",
    "            #     if 10 not in color_dict:\n",
    "            #         colorize(images[i], labels[i].item(), color_dict)\n",
    "            #     else:\n",
    "            #         colorize_gaussian(images[i], labels[i].item(), color_dict)\n",
    "            #     # images[i] = inv_normalize(images[i])\n",
    "\n",
    "            # Add extra dimension for the network\n",
    "            images = images.unsqueeze(1)\n",
    "\n",
    "            # print(images.shape)\n",
    "\n",
    "            # Put images\n",
    "            images = images.cuda()\n",
    "\n",
    "            # Predicted labels\n",
    "            preds = model(images)\n",
    "\n",
    "            # Top predictions per image\n",
    "            _, top_preds = torch.max(preds, 1)\n",
    "\n",
    "            # Predictions and images back on cpu\n",
    "            top_preds = top_preds.cpu()\n",
    "            images = images.cpu()\n",
    "            \n",
    "            # Check the predicted\n",
    "            for i in range(len(labels)):\n",
    "                if top_preds[i].item() == labels[i].item():\n",
    "                    right_dict[top_preds[i].item()] += 1\n",
    "                else:\n",
    "                    wrong_dict[labels[i].item()][top_preds[i].item()] += 1\n",
    "\n",
    "            # Amount of correct predictions\n",
    "            predictions = [top_preds[i].item() == labels[i].item() for i in range(len(labels))]\n",
    "            correct = np.sum(predictions)\n",
    "            \n",
    "            # if np.sum(predictions) < len(labels):\n",
    "            #     print(\"hi\")\n",
    "            #     images = images.squeeze(1)\n",
    "            #     # Show batch images\n",
    "            #     # fig, axs = plt.subplots(4,8, figsize=(28, 28), facecolor='w', edgecolor='k')\n",
    "            #     # fig.subplots_adjust(hspace = .5, wspace=.001)\n",
    "            #     # axs = axs.ravel()\n",
    "            #     # for i in range(len(images)):\n",
    "            #     #     axs[i].imshow(images[i].permute(1, 2, 0))\n",
    "                \n",
    "                \n",
    "#                 index = predictions.index(0)\n",
    "                \n",
    "#                 plt.imshow(images[index].permute(1, 2, 0))\n",
    "#                 plt.show()\n",
    "                \n",
    "#                 print(index, \"True:\", labels[index].item(), \"False:\", top_preds[index].item())\n",
    "                # break\n",
    "\n",
    "            # Update total correct and total images\n",
    "            test_correct += correct\n",
    "            test_total += len(images)\n",
    "\n",
    "\n",
    "    print(\"Correct\", test_correct, \"/\", test_total, \"Accuracy:\", test_correct / test_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfef2782-056b-4224-bd67-7f1ef054ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for x in right_dict:\n",
    "    print(x, \":\", right_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09e339-9113-4cbd-ada2-f329fee7d932",
   "metadata": {},
   "outputs": [],
   "source": [
    "hm = []\n",
    "for i, x in enumerate(wrong_dict):\n",
    "    hm.append([])\n",
    "    for y in wrong_dict[x]:\n",
    "        hm[i].append(wrong_dict[x][y])\n",
    "    # print(x, \":\", wrong_dict[x])\n",
    "print(hm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebff34f1-527a-4e78-a8d8-dcaaa6f1efc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(hm, cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35373e42-0ad7-4ac5-9389-7332fe5e961c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
